{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-Stacked-LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonorand/keras-learn/blob/master/keras_Stacked_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU_tDeBSEYkU",
        "colab_type": "text"
      },
      "source": [
        "#Stacked LSTM for sequence classification\n",
        "In this model, we stack 3 LSTM layers on top of each other, making the model capable of learning higher-level temporal representations.\n",
        "\n",
        "The first two LSTMs return their full output sequences, but the last one only returns the last step in its output sequence, thus dropping the temporal dimension (i.e. converting the input sequence into a single vector).\n",
        "\n",
        "stacked LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH5LH2Q9Dgf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "85bdf83f-2b8a-47be-f2e5-023fc98fb37e"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "data_dim = 16\n",
        "timesteps = 8\n",
        "num_classes = 10\n",
        "\n",
        "# expected input data shape: (batch_size, timesteps, data_dim)\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, return_sequences=True,\n",
        "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
        "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
        "model.add(LSTM(32))  # return a single vector of dimension 32\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Generate dummy training data\n",
        "x_train = np.random.random((1000, timesteps, data_dim))\n",
        "y_train = np.random.random((1000, num_classes))\n",
        "\n",
        "# Generate dummy validation data\n",
        "x_val = np.random.random((100, timesteps, data_dim))\n",
        "y_val = np.random.random((100, num_classes))\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=64, epochs=5,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 100 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 11.5959 - acc: 0.1030 - val_loss: 11.2996 - val_acc: 0.0900\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 1s 700us/step - loss: 11.5939 - acc: 0.0970 - val_loss: 11.3012 - val_acc: 0.0500\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 1s 709us/step - loss: 11.5937 - acc: 0.0980 - val_loss: 11.2998 - val_acc: 0.1300\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 1s 730us/step - loss: 11.5932 - acc: 0.1050 - val_loss: 11.3013 - val_acc: 0.1200\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 1s 796us/step - loss: 11.5926 - acc: 0.0970 - val_loss: 11.3003 - val_acc: 0.0800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f214b1cc390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    }
  ]
}